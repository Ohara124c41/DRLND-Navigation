{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "Train an agent to collect tasty yellow bananas! Oh no, not the blue ones!\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"files/images/banana_collector_firstview.gif\" align=\"center\"></td>\n",
    "    <td><img src=\"files/images/banana_collector_topview.gif\" align=\"center\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Modules & Packages\n",
    "\n",
    "Get all the necessary modules to run this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:06:04.678351Z",
     "start_time": "2019-04-03T05:06:03.513694Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THE LINES IN THIS CELL\n",
    "import os.path as osp\n",
    "from collections import deque\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dqn_agent import Agent\n",
    "\n",
    "STATE_SIZE  = 37\n",
    "ACTION_SIZE = 4\n",
    "BRAIN_NAME  = \"BananaBrain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the Environment\n",
    "\n",
    "Let's take a look at what this environment looks like.\n",
    "\n",
    "Starting from loading the environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Finding the Environment File\n",
    "\n",
    "If you haven't already downloaded the environment file, please do so before we begin.\n",
    "\n",
    "The links can be found in my README file [here](https://github.com/dragonoken/Udacity-DRL-Nanodegree-Navigation-Project).\n",
    "\n",
    "Then, the next cell below will automatically find the environment file in the same directory.\n",
    "\n",
    "If you have downloaded the files somewhere else, or renamed it for some reason, you need to specify the file path to the environment file manually at the bottom of the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:06:05.925529Z",
     "start_time": "2019-04-03T05:06:05.910570Z"
    }
   },
   "outputs": [],
   "source": [
    "env_file_path = \"Banana_Windows_x86_64/Banana.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Watch the Environment with Random Actions\n",
    "\n",
    "The next code cell will start the environment and show you how it looks when taking random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T03:22:09.313970Z",
     "start_time": "2019-04-01T03:21:33.744882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score at 59: -1.0"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_file_path)\n",
    "env_info = env.reset(train_mode=False)[BRAIN_NAME] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "t = 0\n",
    "while True:\n",
    "    action = np.random.randint(ACTION_SIZE)        # select an action\n",
    "    env_info = env.step(action)[BRAIN_NAME]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    t += 1\n",
    "    print(\"\\rCurrent score at {}: {}\".format(t, score), end='')\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"\\nFinal Score: {}\".format(score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Your Own Agent!\n",
    "\n",
    "You can train your own agent to solve this environment in this section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set Hyperparameters and Training Parameters\n",
    "\n",
    "You will be using my baseline agent algorithm, but you can totally adjust many of its hyperparameters in the cell below!\n",
    "\n",
    "Try playing with various hyperparameters and training parameters here.\n",
    "\n",
    "See if you can find a set of parameters that can solve the environment with the least number of episodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:06:27.371920Z",
     "start_time": "2019-04-03T05:06:27.359952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "hyperparams = {\n",
    "    'seed':                3,       # random seed\n",
    "    'buffer_size':         100000,  # size of the experience replay buffer\n",
    "    'batch_size':          8,       # number of experiences to sample at each learning step\n",
    "    'start_since':         8,       # number of experiences to store before it begins learning (must be bigger than 'batch_size')\n",
    "    'gamma':               0.99,    # discount factor\n",
    "    'target_update_every': 1,       # how often to update the target network\n",
    "    'tau':                 1e-3,    # how much to update the target network at every update\n",
    "    'lr':                  5e-4,    # learning rate\n",
    "    'update_every':        1,       # how often to update the online network\n",
    "    'priority_eps':        1e-3,    # small values added to priorities in order to have nonzero priorities\n",
    "    'a':                   0.5,     # priority exponent parameter\n",
    "    'n_multisteps':        3,       # number of steps to consider for multistep learning\n",
    "    'v_min':               -10,     # minimum support value for distributional learning\n",
    "    'v_max':               10,      # maximum support value for distributional learning\n",
    "    'n_atoms':             51,      # number of supports for distributional learning\n",
    "    'initial_sigma':       0.05,    # initial noise parameter value for noisy net\n",
    "    'linear_type':         'noisy', # which linear layers to use ('linear' or 'noisy'; 'linear' to disable noisy net)\n",
    "    'factorized':          False    # whether to use factorized gaussian noise or not\n",
    "}\n",
    "\n",
    "# Training Parameters\n",
    "\n",
    "train_params = {\n",
    "    'n_episodes': 100,                                    # number of episodes to train the agent for\n",
    "    'eps_start':  0.,   'eps_end':  0.,  'eps_decay': 0., # initial, minimum epsilon values and decay rate for epsilon-greedy policy\n",
    "    'beta_start': 0.4,   'beta_end': 1.0                  # importance-sampling weight for prioritized experience replay\n",
    "}\n",
    "\n",
    "temporal_memory_length = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Initialize the Agent\n",
    "\n",
    "The next code cell below will now initialize an agent using the hyperparameter settings above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:06:28.862437Z",
     "start_time": "2019-04-03T05:06:28.837517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (fc0): Linear(in_features=370, out_features=256, bias=True)\n",
       "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3_s): NoisyLinear(in_features=256, out_features=128, bias=True, initial_sigma=0.05, factorized=False)\n",
       "  (fc3_a): NoisyLinear(in_features=256, out_features=128, bias=True, initial_sigma=0.05, factorized=False)\n",
       "  (fc4_s): NoisyLinear(in_features=128, out_features=51, bias=True, initial_sigma=0.05, factorized=False)\n",
       "  (fc4_a): NoisyLinear(in_features=128, out_features=204, bias=True, initial_sigma=0.05, factorized=False)\n",
       "  (hidden_activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Agent(state_size=STATE_SIZE * temporal_memory_length, action_size=ACTION_SIZE, **hyperparams)\n",
    "\n",
    "agent.qnetwork_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train the Agent\n",
    "\n",
    "Finally, you can start training your agent in the cell below!\n",
    "\n",
    "This process will take some time, depending on your computer's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T06:00:49.171865Z",
     "start_time": "2019-04-03T05:06:34.880870Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 | Total Steps: 30000 | Current Score:  14 | Positive Score:  14 | Negative Score:   0 | Average Score:   3.82 | Epsilon: 0.0000 | A: 0.5000 | Beta: 1.0000 | Avg Noise Magnitude: 0.0460 +- 0.0315          \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You may set `no_graphics=True` for speeding up the training process\n",
    "env = UnityEnvironment(file_name=env_file_path, seed=hyperparams['seed'], no_graphics=True)\n",
    "\n",
    "def dqn(n_episodes=2000,\n",
    "        eps_start=1.0, eps_end=0.01, eps_decay=0.995,\n",
    "        beta_start=0., beta_end=1.0,\n",
    "        continue_after_solved=True):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        beta_start (float): initial importance-sampling weight for prioritized experience replay\n",
    "        beta_end (float): final importance-sampling weight for prioritized experience replay\n",
    "        continue_after_solved (bool): whether to continue training after reaching the average score 12\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "\n",
    "    agent.beta = beta_start\n",
    "    beta_increment = (beta_end - beta_start) / n_episodes\n",
    "    \n",
    "    noisy_params = [param for name, param in agent.qnetwork_local.named_parameters() if name.endswith('noisy_weight') or name.endswith('noisy_bias')]\n",
    "        \n",
    "    solved = False\n",
    "    epi_str_max_len = len(str(n_episodes))\n",
    "    total_steps_str_max_len = len(str(n_episodes * 300))\n",
    "    n_steps_taken = 0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[BRAIN_NAME]\n",
    "        temporal_memory = deque([np.zeros(STATE_SIZE) for _ in range(temporal_memory_length - 1)]\n",
    "                                + [env_info.vector_observations[0]], maxlen=temporal_memory_length)\n",
    "#         state = env_info.vector_observations[0]\n",
    "        state = np.concatenate(temporal_memory)\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        t = 0\n",
    "        while True:\n",
    "            action     = int(agent.act(state, eps))\n",
    "            env_info   = env.step(action)[BRAIN_NAME]\n",
    "            temporal_memory.append(env_info.vector_observations[0])\n",
    "#             next_state = env_info.vector_observations[0]\n",
    "            next_state = np.concatenate(temporal_memory)\n",
    "            reward     = env_info.rewards[0]\n",
    "            done       = env_info.local_done[0]\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if reward > 0:\n",
    "                pos_score += reward\n",
    "            elif reward < 0:\n",
    "                neg_score += reward\n",
    "            t += 1\n",
    "            if done:\n",
    "                break\n",
    "        else: # if not done (reached max_t)\n",
    "            agent.memory.reset_multisteps()\n",
    "        n_steps_taken += t\n",
    "        score = pos_score + neg_score\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        agent.beta = min(beta_end, agent.beta + beta_increment)\n",
    "        report_str = \"\\rEpisode {:>{epi_max_len}d} | Total Steps: {:>{total_steps_max_len}d} | Current Score: {:>3.0f}\"\\\n",
    "                     \" | Positive Score: {:>3.0f} | Negative Score: {:>3.0f} | Average Score: {:>6.2f} | Epsilon: {:>6.4f}\"\\\n",
    "                     \" | A: {:>6.4f} | Beta: {:>6.4f}\"\\\n",
    "                     .format(i_episode, n_steps_taken, score, pos_score, neg_score, np.mean(scores_window),\n",
    "                             eps, agent.a, agent.beta, epi_max_len=epi_str_max_len,\n",
    "                             total_steps_max_len=total_steps_str_max_len)\n",
    "        if noisy_params:\n",
    "            flattened_abs_noise = np.concatenate([param.data.abs().cpu().numpy().reshape((-1,)) for param in noisy_params])\n",
    "            report_str += \" | Avg Noise Magnitude: {:>6.4f} +- {:<6.4f}\".format(np.mean(flattened_abs_noise), np.std(flattened_abs_noise))\n",
    "        report_str += \"          \"\n",
    "        if i_episode % 100 == 0:\n",
    "            report_str += '\\n'\n",
    "        print(report_str, end=\"\")\n",
    "        if not solved and np.mean(scores_window) >= 13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            solved = True\n",
    "            if not continue_after_solved:\n",
    "                break\n",
    "    return scores\n",
    "\n",
    "scores = dqn(**train_params,\n",
    "             continue_after_solved=True)\n",
    "\n",
    "env.close()\n",
    "\n",
    "# plot the scores\n",
    "plt.rcParams['figure.facecolor'] = 'w'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Save the Trained Agent\n",
    "\n",
    "Don't forget to save your trained agent!\n",
    "\n",
    "Save your agents parameters, hyperparameters, and training parameters along with the scores it received during the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T19:06:00.377783Z",
     "start_time": "2019-03-28T19:06:00.367810Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'model_dict': agent.qnetwork_local.state_dict(),\n",
    "            'scores': scores,\n",
    "            'hyperparams': hyperparams,\n",
    "            'train_params': train_params}, 'my_agent.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Watch the Smart Agent\n",
    "\n",
    "Now it's time to watch the smart agentmy pretrained one or your owncollecting delicious bananas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Loading the Saved Agent Model\n",
    "\n",
    "You first need to load the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T19:06:17.774651Z",
     "start_time": "2019-03-28T19:06:17.767669Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    loaded_dict = torch.load(filepath, map_location=torch.device('cpu'))\n",
    "    agent = Agent(state_size=STATE_SIZE, action_size=ACTION_SIZE, **loaded_dict['hyperparams'])\n",
    "    agent.qnetwork_local.load_state_dict(loaded_dict['model_dict'])\n",
    "    agent.qnetwork_target.load_state_dict(loaded_dict['model_dict'])\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the file path in the cell below according to the location of the save file you want to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T19:06:18.787185Z",
     "start_time": "2019-03-28T19:06:18.744300Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = load_model(\"./pretrained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Watch the Smart Agent\n",
    "\n",
    "Now, the next cell will show you the loaded agent in action in real time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T04:02:20.457914Z",
     "start_time": "2019-03-31T04:01:39.531513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a250bac9fe1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_graphics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBRAIN_NAME\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# reset the environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m            \u001b[1;31m# get the current state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m                                          \u001b[1;31m# initialize the score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0maca_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[1;34m(self, init_parameters)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \"or use a different worker number.\".format(str(self.worker_id)))\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[0;32m     60\u001b[0m                 \u001b[1;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_check_closed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"handle is closed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: handle is closed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [WinError 232] The pipe is being closed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\grpc\\_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_file_path, no_graphics=True)\n",
    "\n",
    "env_info = env.reset(train_mode=False)[BRAIN_NAME] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "t = 0                                              # initialize the time step count\n",
    "while True:\n",
    "    action = int(agent.act(state))                 # select an action\n",
    "    env_info = env.step(action)[BRAIN_NAME]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    t += 1\n",
    "    print(\"\\rCurrent score at {}: {}\".format(t, score), end='')\n",
    "    sleep(0.025)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "\n",
    "print(\"\\nFinal Score: {}\".format(score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Performance Estimation\n",
    "\n",
    "Usually it's better to run many episodes to get a much accurate estimate of an agent's performance.\n",
    "\n",
    "The code cell below will run the agent at a fast-forward speed and show you the average performance over multiple episodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T00:13:28.514208Z",
     "start_time": "2019-04-04T00:10:36.110899Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5d115dc603e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_graphics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m    \u001b[1;31m# total number of episodes to run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtotal_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m     \u001b[1;31m# initialize the cumulative score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlast_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m      \u001b[1;31m# initualize the previous score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0maca_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[1;34m(self, init_parameters)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \"or use a different worker number.\".format(str(self.worker_id)))\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[0;32m     60\u001b[0m                 \u001b[1;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_check_closed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"handle is closed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: handle is closed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [WinError 232] The pipe is being closed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\grpc\\_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\site-packages\\unityagents\\rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"C:\\Users\\ohara\\AppData\\Local\\conda\\conda\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 280, in _send_bytes\n",
      "    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n",
      "BrokenPipeError: [WinError 232] The pipe is being closed\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_file_path, no_graphics=False)\n",
    "\n",
    "n_episodes = 100    # total number of episodes to run\n",
    "total_score = 0     # initialize the cumulative score\n",
    "last_score = 0      # initualize the previous score\n",
    "report_str_format = \"\\rEpisode {{{}}} | Current Score {{:>4.1f}} | Last Score {{:>4.1f}} | Average Score {{:>5.2f}}\".format(\":>{}d\".format(len(str(n_episodes))))\n",
    "for n in range(1, n_episodes + 1):\n",
    "    env_info = env.reset(train_mode=True)[BRAIN_NAME]  # reset the environment\n",
    "    temporal_memory = deque([np.zeros(STATE_SIZE) for _ in range(temporal_memory_length - 1)]\n",
    "                             + [env_info.vector_observations[0]], maxlen=temporal_memory_length)\n",
    "#     state = env_info.vector_observations[0]            # get the current state\n",
    "    state = np.concatenate(temporal_memory)\n",
    "    score = 0                                          # initialize the score\n",
    "    while True:\n",
    "        action = int(agent.act(state))                 # select an action\n",
    "        env_info = env.step(action)[BRAIN_NAME]        # send the action to the environment\n",
    "        temporal_memory.append(env_info.vector_observations[0])\n",
    "#         next_state = env_info.vector_observations[0]   # get the next state\n",
    "        next_state = np.concatenate(temporal_memory)\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        print(report_str_format.format(n, score, last_score, total_score / n), end='')\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "    last_score = score\n",
    "    total_score += score\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "I hope you had fun here!\n",
    "\n",
    "Happy Deep Reinforcement Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
